<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>&lt;think>...&lt;/think> QwQ-Max-Preview | inclusionAI</title><meta name=keywords content><meta name=description content="QWEN CHAT DISCORD
This is a blog created by QwQ-Max-Preview. We hope you enjoy it!
Introduction <think>
Okay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned. First, the model is part of the Qwen series, built on Qwen2.5-Max. It&rsquo;s a preview version, so they probably want to highlight that it&rsquo;s a sneak peek before the full release."><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://Biao-Gong.github.io/blog/qwq-max-preview/><link crossorigin=anonymous href=/assets/css/stylesheet.f2c8c5c99d640d6833f4f42ed8c3a7b5281f71b42b0ebb44177bf32898dbaea1.css integrity="sha256-8sjFyZ1kDWgz9PQu2MOntSgfcbQrDrtEF3vzKJjbrqE=" rel="preload stylesheet" as=style><link rel=icon href=https://Biao-Gong.github.io/favicon.png><link rel=apple-touch-icon href=https://Biao-Gong.github.io/favicon.png><link rel=manifest href=https://Biao-Gong.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://Biao-Gong.github.io/blog/qwq-max-preview/><link rel=alternate hreflang=zh href=https://Biao-Gong.github.io/zh/blog/qwq-max-preview/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="<think>...</think> QwQ-Max-Preview"><meta property="og:description" content="QWEN CHAT DISCORD
This is a blog created by QwQ-Max-Preview. We hope you enjoy it!
Introduction <think>
Okay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned. First, the model is part of the Qwen series, built on Qwen2.5-Max. It&rsquo;s a preview version, so they probably want to highlight that it&rsquo;s a sneak peek before the full release."><meta property="og:type" content="article"><meta property="og:url" content="https://Biao-Gong.github.io/blog/qwq-max-preview/"><meta property="og:image" content="https://Biao-Gong.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-02-25T02:00:04+08:00"><meta property="article:modified_time" content="2025-02-25T02:00:04+08:00"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Biao-Gong.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="<think>...</think> QwQ-Max-Preview"><meta name=twitter:description content="QWEN CHAT DISCORD
This is a blog created by QwQ-Max-Preview. We hope you enjoy it!
Introduction <think>
Okay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned. First, the model is part of the Qwen series, built on Qwen2.5-Max. It&rsquo;s a preview version, so they probably want to highlight that it&rsquo;s a sneak peek before the full release."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://Biao-Gong.github.io/blog/"},{"@type":"ListItem","position":2,"name":"\u003cthink\u003e...\u003c/think\u003e QwQ-Max-Preview","item":"https://Biao-Gong.github.io/blog/qwq-max-preview/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"... QwQ-Max-Preview","name":"... QwQ-Max-Preview","description":"QWEN CHAT DISCORD\nThis is a blog created by QwQ-Max-Preview. We hope you enjoy it!\nIntroduction \u0026lt;think\u0026gt;\nOkay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned. First, the model is part of the Qwen series, built on Qwen2.5-Max. It\u0026rsquo;s a preview version, so they probably want to highlight that it\u0026rsquo;s a sneak peek before the full release.","keywords":[],"articleBody":" QWEN CHAT DISCORD\nThis is a blog created by QwQ-Max-Preview. We hope you enjoy it!\nIntroduction Okay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned. First, the model is part of the Qwen series, built on Qwen2.5-Max. It’s a preview version, so they probably want to highlight that it’s a sneak peek before the full release. The main strengths are deep reasoning, math, coding, general domains, and Agent-related tasks. They also mention future updates and open-sourcing under Apache 2.0. For the title, I need to make it catchy and include the model name. Maybe something like “Introducing QwQ-Max-Preview: The Next Leap in Deep Reasoning and Multi-Domain Mastery”. That highlights the preview status and the key features. The introduction should summarize the announcement. Start with excitement about the release. Mention it’s built on Qwen2.5-Max, emphasize reasoning, math, coding, and Agent tasks. Note that it’s a preview with upcoming updates and eventual open-source. Keep it concise without explanations, as per the user’s request. Make sure to use bold for the model name and key terms for emphasis. Avoid any markdown and keep paragraphs short. Let me check if I covered all points: model name, based on Qwen2.5, preview status, strengths in reasoning/math/coding/Agent tasks, future updates, open-source under Apache 2.0. Yes, that’s all there. Alright, time to put it together. We’re happy to unveil QwQ-Max-Preview , the latest advancement in the Qwen series, designed to push the boundaries of deep reasoning and versatile problem-solving. Built on the robust foundation of Qwen2.5-Max , this preview model excels in mathematics, coding, and general-domain tasks, while delivering outstanding performance in Agent-related workflows. As a sneak peek into our upcoming QwQ-Max release, this version offers a glimpse of its enhanced capabilities, with ongoing refinements and an official Apache 2.0-licensed open-source launch of QwQ-Max and Qwen2.5-Max planned soon. Stay tuned for a new era of intelligent reasoning. Cases Coding Next QwQ-Max-Preview Game Next QwQ-Max-Preview Game Next QwQ-Max-Preview Agent Next QwQ-Max-Preview Agent Next QwQ-Max-Preview Math Next QwQ-Max-Preview Creative Writing Next QwQ-Max-Preview Search Next QwQ-Max-Preview Future Work Okay, the user wants me to write a future work section for their blog post. They mentioned that besides open-sourcing QwQ-Max, they’re planning to release an APP and open-source smaller reasoning models like QwQ-32B for developers to use locally. First, I need to structure this section clearly. The title should reflect the future plans. Maybe something like “Looking Ahead: Expanding Accessibility and Innovation”. That sounds forward-looking. Next, the introduction should summarize the upcoming releases. Mention the open-source of QwQ-Max under Apache 2.0, the Qwen Chat APP for broader access, and the smaller models like QwQ-32B. Highlight that these models are for local use, which is important for developers concerned about privacy or resource constraints. Then, break it into subsections. First, the Qwen Chat APP release. Need to explain its features: user-friendly interface, real-time reasoning, collaboration tools. Emphasize accessibility for non-technical users and integration with existing workflows. Second, the open-source smaller models. Mention QwQ-32B as an example. Explain benefits: low latency, privacy, customization. Target audience: developers, researchers, hobbyists. Third, community-driven innovation. Encourage collaboration, contributions, and feedback. Mention fostering ecosystem for AI applications. Finally, a closing paragraph that ties it all together. Reiterate commitment to open-source and empowering the community. Invite readers to join the journey. Check if all points are covered: APP, smaller models, open-source, Apache license, local usage, different audiences. Avoid technical jargon but keep it professional. Make sure it flows well and each section transitions smoothly. Also, ensure the tone matches the excitement from the initial announcement. No markdown, just plain text with clear headings. Alright, that should cover the user’s requirements. As we prepare for the official open-source release of QwQ-Max under the Apache 2.0 License, our roadmap extends beyond sharing cutting-edge research. We are committed to democratizing access to advanced reasoning capabilities and fostering innovation across diverse applications. Here’s what’s next:\nAPP Release To bridge the gap between powerful AI and everyday users, we will launch a dedicated APP for Qwen Chat. This intuitive interface will enable seamless interaction with the model for tasks like problem-solving, code generation, and logical reasoning—no technical expertise required. The app will prioritize real-time responsiveness and integration with popular productivity tools, making advanced AI accessible to a global audience.\nOpen-Sourcing Smaller Reasoning Models Recognizing the need for lightweight, resource-efficient solutions, we will release a series of smaller QwQ variants , such as QwQ-32B, for local device deployment. These models will retain robust reasoning capabilities while minimizing computational demands, allowing developers to integrate them into devices. Perfect for privacy-sensitive applications or low-latency workflows, they will empower creators to build custom AI solutions.\nCommunity-Driven Innovation By open-sourcing QwQ-Max, Qwen2.5-Max, and its smaller counterparts, we aim to spark collaboration among developers, researchers, and hobbyists. We invite the community to experiment, fine-tune, and extend these models for specialized use cases—from education tools to autonomous agents. Our goal is to cultivate an ecosystem where innovation thrives through shared knowledge and collective problem-solving.\nStay tuned as we roll out these initiatives, designed to empower users at every level and redefine the boundaries of what AI can achieve. Together, we’re building a future where intelligence is not just powerful, but universally accessible.\n","wordCount":"884","inLanguage":"en","datePublished":"2025-02-25T02:00:04+08:00","dateModified":"2025-02-25T02:00:04+08:00","author":{"@type":"Person","name":"inclusionAI, Ant Group"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://Biao-Gong.github.io/blog/qwq-max-preview/"},"publisher":{"@type":"Organization","name":"inclusionAI","logo":{"@type":"ImageObject","url":"https://Biao-Gong.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://Biao-Gong.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>&lt;think>...&lt;/think> QwQ-Max-Preview</h1><div class=post-meta><span title='2025-02-25 02:00:04 +0800 +0800'>February 25, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;884 words&nbsp;·&nbsp;inclusionAI, Ant Group&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://Biao-Gong.github.io/zh/blog/qwq-max-preview/>简体中文</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-banner-en.jpg width=100%></figure><p><a href=https://chat.qwen.ai class="btn external" target=_blank>QWEN CHAT</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><p>This is a blog created by QwQ-Max-Preview. We hope you enjoy it!</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><blockquote><p><span style=font-size:smaller;color:blue>&lt;think></span><br><i style=font-size:smaller;color:grey>Okay, the user wants me to create a title and introduction for their blog announcing the release of QwQ-Max-Preview. Let me start by understanding the key points they mentioned.<br><br>First, the model is part of the Qwen series, built on Qwen2.5-Max. It&rsquo;s a preview version, so they probably want to highlight that it&rsquo;s a sneak peek before the full release. The main strengths are deep reasoning, math, coding, general domains, and Agent-related tasks. They also mention future updates and open-sourcing under Apache 2.0.<br><br>For the title, I need to make it catchy and include the model name. Maybe something like &ldquo;Introducing QwQ-Max-Preview: The Next Leap in Deep Reasoning and Multi-Domain Mastery&rdquo;. That highlights the preview status and the key features.<br><br>The introduction should summarize the announcement. Start with excitement about the release. Mention it&rsquo;s built on Qwen2.5-Max, emphasize reasoning, math, coding, and Agent tasks. Note that it&rsquo;s a preview with upcoming updates and eventual open-source. Keep it concise without explanations, as per the user&rsquo;s request. Make sure to use bold for the model name and key terms for emphasis. Avoid any markdown and keep paragraphs short. Let me check if I covered all points: model name, based on Qwen2.5, preview status, strengths in reasoning/math/coding/Agent tasks, future updates, open-source under Apache 2.0. Yes, that&rsquo;s all there. Alright, time to put it together.</i><br><span style=font-size:smaller;color:blue>&lt;/think></span></p></blockquote><p>We’re happy to unveil QwQ-Max-Preview , the latest advancement in the Qwen series, designed to push the boundaries of deep reasoning and versatile problem-solving. Built on the robust foundation of Qwen2.5-Max , this preview model excels in mathematics, coding, and general-domain tasks, while delivering outstanding performance in Agent-related workflows. As a sneak peek into our upcoming QwQ-Max release, this version offers a glimpse of its enhanced capabilities, with ongoing refinements and an official Apache 2.0-licensed open-source launch of QwQ-Max and Qwen2.5-Max planned soon. Stay tuned for a new era of intelligent reasoning.<br><br></p><h2 id=cases>Cases<a hidden class=anchor aria-hidden=true href=#cases>#</a></h2><div class="full-width-container example-container"><div class=example-content><div class=title><span>Coding</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-coder.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Game</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-game.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Game</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-game2.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Agent</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-agent.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Agent</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-agent-zh.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Math</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-math.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Creative Writing</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-creative-writing.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Search</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role>QwQ-Max-Preview</div><div class=content><figure><video controls src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-search.mp4></video></figure></div></div></div></div><h2 id=future-work>Future Work<a hidden class=anchor aria-hidden=true href=#future-work>#</a></h2><blockquote><p><span style=font-size:smaller;color:blue>&lt;think></span><br><i style=font-size:smaller;color:grey>Okay, the user wants me to write a future work section for their blog post. They mentioned that besides open-sourcing QwQ-Max, they&rsquo;re planning to release an APP and open-source smaller reasoning models like QwQ-32B for developers to use locally.<br><br>First, I need to structure this section clearly. The title should reflect the future plans. Maybe something like &ldquo;Looking Ahead: Expanding Accessibility and Innovation&rdquo;. That sounds forward-looking.<br><br>Next, the introduction should summarize the upcoming releases. Mention the open-source of QwQ-Max under Apache 2.0, the Qwen Chat APP for broader access, and the smaller models like QwQ-32B. Highlight that these models are for local use, which is important for developers concerned about privacy or resource constraints.<br><br>Then, break it into subsections. First, the Qwen Chat APP release. Need to explain its features: user-friendly interface, real-time reasoning, collaboration tools. Emphasize accessibility for non-technical users and integration with existing workflows.<br><br>Second, the open-source smaller models. Mention QwQ-32B as an example. Explain benefits: low latency, privacy, customization. Target audience: developers, researchers, hobbyists.<br><br>Third, community-driven innovation. Encourage collaboration, contributions, and feedback. Mention fostering ecosystem for AI applications.<br><br>Finally, a closing paragraph that ties it all together. Reiterate commitment to open-source and empowering the community. Invite readers to join the journey.<br><br>Check if all points are covered: APP, smaller models, open-source, Apache license, local usage, different audiences. Avoid technical jargon but keep it professional. Make sure it flows well and each section transitions smoothly. Also, ensure the tone matches the excitement from the initial announcement. No markdown, just plain text with clear headings. Alright, that should cover the user&rsquo;s requirements.</i><br><span style=font-size:smaller;color:blue>&lt;/think></span></p></blockquote><p>As we prepare for the official open-source release of QwQ-Max under the Apache 2.0 License, our roadmap extends beyond sharing cutting-edge research. We are committed to democratizing access to advanced reasoning capabilities and fostering innovation across diverse applications. Here’s what’s next:</p><ol><li><p><strong>APP Release</strong>
To bridge the gap between powerful AI and everyday users, we will launch a dedicated APP for Qwen Chat. This intuitive interface will enable seamless interaction with the model for tasks like problem-solving, code generation, and logical reasoning—no technical expertise required. The app will prioritize real-time responsiveness and integration with popular productivity tools, making advanced AI accessible to a global audience.</p></li><li><p><strong>Open-Sourcing Smaller Reasoning Models</strong>
Recognizing the need for lightweight, resource-efficient solutions, we will release a series of smaller QwQ variants , such as QwQ-32B, for local device deployment. These models will retain robust reasoning capabilities while minimizing computational demands, allowing developers to integrate them into devices. Perfect for privacy-sensitive applications or low-latency workflows, they will empower creators to build custom AI solutions.</p></li><li><p><strong>Community-Driven Innovation</strong>
By open-sourcing QwQ-Max, Qwen2.5-Max, and its smaller counterparts, we aim to spark collaboration among developers, researchers, and hobbyists. We invite the community to experiment, fine-tune, and extend these models for specialized use cases—from education tools to autonomous agents. Our goal is to cultivate an ecosystem where innovation thrives through shared knowledge and collective problem-solving.</p></li></ol><p>Stay tuned as we roll out these initiatives, designed to empower users at every level and redefine the boundaries of what AI can achieve. Together, we’re building a future where intelligence is not just powerful, but universally accessible.</p></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://Biao-Gong.github.io/>inclusionAI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>