<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Blog on INCLUSION AI</title>
    <link>https://Biao-Gong.github.io/zh/blog/</link>
    <description>Recent content in Blog on INCLUSION AI</description>
    <image>
      <url>https://Biao-Gong.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://Biao-Gong.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 07 Jul 2025 00:00:04 +0800</lastBuildDate><atom:link href="https://Biao-Gong.github.io/zh/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ Markdown 样板（龚镖-制）]</title>
      <link>https://Biao-Gong.github.io/zh/blog/template/</link>
      <pubDate>Mon, 07 Jul 2025 00:00:04 +0800</pubDate>
      
      <guid>https://Biao-Gong.github.io/zh/blog/template/</guid>
      <description>1. 各种模态的case的markdown样板见英文版，这里就不重复粘贴了。 2. 注意cases里的.json的中文版别漏了。 3. 中文版本的文字部分，注意用词妥当，不要机翻。 GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
注意：QwQ 的发音为 /kwju:/ ，与单词 &amp;ldquo;quill&amp;rdquo; 的读音近似。
思考、质疑、理解，是人类探索未知的永恒追求。在这条探索之路上，QwQ犹如一位怀抱无尽好奇的学徒，以思考和疑问照亮前路。QwQ体现了古老的哲学精神：它深知自己一无所知，而这种认知正是其好奇心的源泉。在探寻答案的过程中，它始终保持自省，以理性之光审视每一个假设，在不同的思维维度中穿行，追寻更深层的真理。
然而，正如所有智慧的追求者一样，QwQ也有其局限性。这个版本只是漫长旅程中的一个初步阶段——它仍在学习如何行走于理性之路。它的思绪偶尔飘散，答案或许未尽完善，智慧仍在积淀。但这就是学习的美妙之处：既有能力又保持谦逊，既有知识又永远充满疑问。我们邀请您与QwQ一同探索，接纳它的洞见与不完美，共同踏上这无尽的理解之旅。
模型局限性 QwQ-32B-Preview 是由 Qwen 团队开发的实验性研究模型，专注于增强 AI 推理能力。作为预览版本，它展现了令人期待的分析能力，同时也存在以下局限：
语言切换问题：模型可能在回答中混合使用不同语言，影响表达的连贯性。
推理循环：在处理复杂逻辑问题时，模型偶尔会陷入递归推理模式，在相似思路中循环。这种行为虽然反映了模型试图全面分析的努力，但可能导致冗长而不够聚焦的回答。
安全性考虑：尽管模型已具备基础安全管控，但仍需要进一步增强。它可能产生不恰当或存在偏见的回答，且与其他大型语言模型一样，可能受到对抗攻击的影响。我们强烈建议用户在生产环境中谨慎使用，并采取适当的安全防护措施。
能力差异：QwQ-32B-Preview 在数学和编程领域表现出色，但在其他领域仍有提升空间。模型性能会随任务的复杂度和专业程度而波动。我们正通过持续优化，努力提升模型的综合能力。
模型表现 通过深入的探索和无数的试验，我们发现了一个深刻的道理：当模型有足够的时间思考、质疑和反思时，它对数学和编程的理解就会深化。就像学生通过认真地检查自己的工作并从错误中学习变得更加聪明一样，我们的模型也通过耐心和深思熟虑的分析获得了更深入的见解。这种细致的反思和自我质疑的过程使得模型能够取得解决复杂问题的突破性进展。我们的探索之旅揭示了模型在数学和编程领域解决一些最具挑战性的问题的卓越能力，包括：
GPQA：一个通过研究生级别问题评估高阶科学解题能力的评测集，旨在考察科学问题解决能力。 AIME：涵盖算术、代数、计数、几何、数论、概率等中学数学主题的综合评测，测试数学问题解决能力。 MATH-500：包含500个测试样本的MATH评测集，全面考察数学解题能力。 LiveCodeBench：评估真实编程场景中代码生成和问题解决能力的高难度评测集。 具体表现如下：
GPQA：65.2%，展示了研究生水平的科学推理能力； AIME：50.0%，证明了强大的数学问题解决技能； MATH-500：90.6%，体现了在各类数学主题上的全面理解； LiveCodeBench：50.0%，验证了在实际编程场景中的出色表现。 这些成果充分体现了QwQ在分析和问题解决能力方面的显著进步，尤其是在需要深度推理的技术领域。
样例 下列样例展示了QwQ深度自省的能力——质疑自身假设、进行深思熟虑的自我对话，并仔细审视其推理过程的每一步。
Example: Logical Reasoning Next User S先生、P先生、Q先生他们知道桌子的抽屉里有16张扑克牌：红桃A、Q、4 黑桃J、8、4、2、7、3 草花K、Q、5、4、6 方块A、5。约翰教授从这16张牌中挑出一张牌来，并把这张牌的点数告诉 P先生，把这张牌的花色告诉Q先生。这时，约翰教授问P先生和Q 先生：你们能从已知的点数或花色中推知这张牌是什么牌吗？于是，S先生听到如下的对话：
P先生：我不知道这张牌。
Q先生：我知道你不知道这张牌。
P先生：现在我知道这张牌了。
Q先生：我也知道了。
请问：这张牌是什么牌？
QwQ-32B-Preview 这道题是逻辑推理题，涉及到信息的逐步披露和推理。题目中有一副16张扑克牌，分别是：
红桃：A、Q、4
黑桃：J、8、4、2、7、3
草花：K、Q、5、4、6
方块：A、5
约翰教授选了一张牌，把点数告诉了P先生，把花色告诉了Q先生。然后通过他们的对话，我们要推断出是哪张牌。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://Biao-Gong.github.io/zh/blog/ming-lite-omni-preview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Biao-Gong.github.io/zh/blog/ming-lite-omni-preview/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://Biao-Gong.github.io/zh/blog/ming-lite-uni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Biao-Gong.github.io/zh/blog/ming-lite-uni/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://Biao-Gong.github.io/zh/blog/ming-omni/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Biao-Gong.github.io/zh/blog/ming-omni/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
